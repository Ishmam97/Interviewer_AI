{
  "resume_content": "Ishmam  Ahmed  Solaiman  ishmam.a.solaiman@gmail.com  •  +1  (945)-900-3383  •  www.ishmamsolaiman.com Professional  Skills  \n Python ,  Langchain,  Langgraph,  Pinecone,  Huggingface,  Transformers,  ETL ,  FastAPI ,  JavaScript ,  \nTypeScript\n,\n \nJava\n,\n \nReact\n,\n \nNodeJS\n,\n \nTensorFlow\n,\n \nMySQL,\n \nMongoDB,\n \nMongoose,\n \nFirebase,\n \nElasticSearch,\n \nJenkins,\n \nKibana,\n \nSentry,\n \nAWS\n,\n \nDocker\n,\n \nKubernetes,\n \nAgile\n \nMethodologies,\n \nScrum,\n \nGit\n.\n \n Experience   Research  Assistant  (Machine  Learning)  -  COSMOS at  UA  Little  Rock                                                2022  Sep  -  2024  May  ●  Developed  and  deployed  a  Multi-Agent  AI-powered  content  discovery  bot  using  various  models  (BERT,  \nGemini,\n \nMistral)\n \nfor\n \nnarrative\n \nextraction,\n \npropagation,\n \nand\n \nanomaly\n \ndetection\n \nfrom\n \nYouTube\n \nvideo\n \ncontent.\n ●  Implemented  AI  moderation  pipelines,  with  integrated  ETL  processes,  extracting  data  from  2,000+  videos  and  \n4M+\n \ncomments,\n \nenabling\n \nLLM-based\n \nsummarization,\n \nachieving\n \n89%\n \naccuracy\n \nin\n \nharmful\n \ncontent\n \ndetection\n.\n ●  Fine-tuned  and  deployed  open-source  models  ( Mistral ,  Deepseek,  Llama )  with  custom  RAG  on  the  \norganization\n \nserver,\n \nexposing\n \ninternal\n \nAPI\ns\n \nfor\n \nfree\n \norganization-wide\n \nusage,\n \nboosting\n \nwork\n \nefficiency.\n \n  Software  Engineering  Intern  -  Gainwell  Technologies                                                                          2023  Apr  -  2023  Aug  ●  Engineered  \"Gabby  AI,\"  an  LLM-powered  conversational  voice  assistant  agent  for  healthcare  call  automation ,  \nimproving\n \nnatural\n \nlanguage\n \nunderstanding\n \nand\n \ngeneration.\n \n(\nLanggraph,\n \nLangchain,\n \nPytorch,\n \nAWS)\n ●  Reduced  average  call  handling  time  by  58  seconds  per  call  through  advanced  NLP  techniques,  optimizing  contact  \ncenter\n \nefficiency,\n \nand\n \nreducing\n \ncosts.\n  Full  Stack  Software  Engineer  I  -  Optimizely                                                                             2021  Jan   -  2022  July  ●  Led  GPT-3  integration  for  the  Smart  Content  feature,  enabling  intelligent  content  generation  and  achieving  600+  \ndaily\n \nactive\n \nusers\n \nwithin\n \n6\n \nmonths.\n \n(\nReact,\n \nTypescript,\n \nMongodb,\n \nGPT3,\n \nAPIs\n)\n ●  Optimized  backend  systems  for  AI  model  inference,  reducing  API  response  times  by  40%  using  Redis  caching,  \nquery\n \noptimization,\n \nand\n \npayload\n \ncompression.\n ●  Improved  code  reliability,  increasing  test  coverage  to  90%  with  Mocha,  Sinon,  and  RTL,  resulting  in  a  50%  \nreduction\n \nin\n \nweekly\n \nbugs.\n  Instructor  of  Computer  Science-  Arkansas  Tech  University                                                       2024  Sep   -  2025  May  ●  Led  Agile ,  Full-Stack  Project  Experience:  Supervised  student  teams  in  Agile-based  projects,  resulting  in  5  fully  \nfunctional\n \nweb\n \nand\n \nmobile\n \napplications\n \nthat\n \nincorporated\n \ndata\n \ndashboards\n \nfor\n \nvisualizing\n \nuser\n \nengagement\n \nand\n \nrecommendation\n \nalgorithms.\n \n ●  Fostered  Data  Proficiency  through  Engaging  Instruction:  Delivered  hands-on  lectures,  achieving  an  87%  student  \nparticipation\n \nrate\n \nand\n \nan\n \noutstanding\n \nfeedback\n \nscore\n \n(4.6/5)\n.\n \n  Education  The  University  of  Arkansas  ( M.Sc.  in  Computer  Science )      2022  Aug  -  2024  May  \nAdvanced\n \nSoftware\n \nEngineering,\n \nInformation\n \nVisualization,\n \nAnalysis\n \nof\n \nAlgorithms,\n \nand\n \nArtificial\n \nIntelligence\n  BRAC  University  ( B.Sc  in  Computer  Science )                                                                        2016  Sep  -  2021  Jan  Data  Structures ,  Algorithms ,  Software  Engineering ,  Computer  architecture,  System  Analysis  and  design,  \nWeb\n \nDevelopment\n,\n \nAndroid\n \ndevelopment,\n \nArtificial\n \nIntelligence\n,\n \nNeural\n \nNetworks\n,\n \nNatural\n \nLanguage\n \nProcessing\n,\n \nStatistics,\n \nCalculus,\n \nComplex\n \nvariables\n \nand\n \nLaplace\n \nTransformations,\n \nDiscrete\n \nmathematics.\n  Publications   1.  Solaiman,  I.,  &  Agarwal,  N.  (2024).  Multiagent-based  Youtube  Content  Discovery  Bot.  In  Proceedings  of  the  2023  IEEE/ACM  ASONAM  '23  (pp.  450–453).  2.  Solaiman,  I.,  Agarwal,  N.,  …  (2024)  Detecting  and  Characterizing  Inorganic  User  Engagement  on  YouTube,  In  Proceedings  of  the  18th  International  AAAI  Conference  on  Web  and  Social  Media,  CySoc  2024.  3.  Solaiman,  I  (2022).  X-Ray  Classification  to  Detect  COVID-19  Using  Ensemble  Model.  In  Proceedings  of  the  14th  International  Conference  on  Agents  and  Artificial  Intelligence  -  Volume  2",
  "job_description": "Remote (US Preferred) | Full-time | Reporting to CTO\nWe’re a fast-moving team reimagining education through AI. Our mission is to deliver personalized, adaptive learning experiences that scale. Backed by leading partners and driven by impact, we’re building tools that empower students and educators every day.\n\n\nApply here: https://www.atypicalai.com/jobs/ai-engineer-agentic-frameworks-in-education\n\n\nJob Description\nWe’re seeking an experienced AI Engineer to help architect and build our agentic content creation framework. You’ll be a core contributor—coding, experimenting, and helping define how AI agents can generate and manage high-quality educational resources aligned to learning standards and personalized learning needs.\n\nKey Responsibilities\nDesign, develop, and deploy agentic systems that create and review learning materials at scale\nCode across our AI stack (Python/Typescript, LangChain, OpenAI/Anthropic/Gemini APIs, Neo4j, etc.)\nLead experiments across fine-tuned LLMs, RAG pipelines, and multi-agent coordination\nStay at the forefront of emerging research and advancements in agentic systems—helping us adopt and contribute to the bleeding edge of the field\nCollaborate with students and educators to understand content needs and learning styles\nEnsure generated content is aligned with curriculum standards and user-specific learning paths\nImplement feedback loops both AI and Human-In-Loop between generation, review, and QA agents to maximize quality and efficiency\nQualifications\nStrong engineering background (Python/Typescript, API integration, backend frameworks)\n2+ years working with LLMs, multi-agent frameworks, or autonomous AI tools\nExperience with educational content or curriculum alignment is a strong plus\nBuilder mentality—bias to action, low ego, and thrives in 0→1 environments\nPassion for using AI to make learning more accessible, engaging, and effective\nWhy Join Atypical?\nAt Atypical, you will have the opportunity to learn every detail about this brave new AI-powered world, and to work on exciting, complex, and deeply meaningful problems, shaping the future of education for decades to come. We offer competitive compensation, unlimited PTO and a flexible work schedule, a learning & development stipend, and more. Join us and be part of a team that values innovation, creativity, and inclusivity.\n\n",
  "interview_plan": [
    {
      "question": "Can you describe your experience with designing and deploying multi-agent AI systems, particularly in the context of content generation or review, and how you ensured their alignment with specific standards or user needs?",
      "category": "experience",
      "priority": 1,
      "expected_skills": [
        "multi-agent frameworks",
        "content creation",
        "alignment with standards"
      ],
      "follow_up_prompts": [
        "What challenges did you face during deployment?",
        "How did you evaluate the quality and effectiveness of the generated content?"
      ]
    },
    {
      "question": "Given your background with LLMs and API integrations, how would you approach experimenting with fine-tuning models like GPT-3 or Gemini for educational content, ensuring both quality and scalability?",
      "category": "technical",
      "priority": 2,
      "expected_skills": [
        "LLMs",
        "API integration",
        "fine-tuning",
        "scalability"
      ],
      "follow_up_prompts": [
        "What metrics would you use to measure success?",
        "How would you handle potential biases or inaccuracies in generated content?"
      ]
    },
    {
      "question": "In a collaborative environment working with educators and students, how do you balance technical innovation with user feedback to improve AI-driven educational tools, and can you provide an example from your past experience?",
      "category": "behavioral",
      "priority": 3,
      "expected_skills": [
        "collaboration",
        "user feedback",
        "adaptability",
        "soft skills"
      ],
      "follow_up_prompts": [
        "How do you handle conflicting feedback?",
        "What strategies do you use to ensure the technology remains accessible and engaging?"
      ]
    }
  ],
  "current_question_idx": 3,
  "current_question": "In a collaborative environment working with educators and students, how do you balance technical innovation with user feedback to improve AI-driven educational tools, and can you provide an example from your past experience?",
  "candidate_response": "bruh",
  "interview_notes": [
    {
      "question": "Can you describe your experience with designing and deploying multi-agent AI systems, particularly in the context of content generation or review, and how you ensured their alignment with specific standards or user needs?",
      "response": "no",
      "timestamp": "2025-05-31T15:58:30.505698",
      "score": 2,
      "analysis": "SCORE: 2\n\nSTRENGTHS:  \n- The candidate’s response indicates a lack of experience or familiarity with designing and deploying multi-agent AI systems, which is a core requirement for the role.  \n- No demonstrated knowledge of content generation, review processes, or alignment with standards and user needs.\n\nCONCERNS:  \n- The response \"no\" suggests minimal or no relevant experience in multi-agent AI systems, especially in the context of content creation or review.  \n- Does not provide any examples or details about working with AI agents, LLMs, or related frameworks.  \n- Fails to address the key responsibilities such as designing, deploying, or experimenting with agentic systems, which are central to the role.  \n- Lacks evidence of familiarity with the technical stack (Python, Typescript, APIs, LangChain, etc.) or research in agentic AI.\n\nFOLLOW_UP:  \n- Can you describe any experience you have with multi-agent frameworks or autonomous AI tools?  \n- Have you worked on projects involving content generation, review, or alignment with standards?  \n- How familiar are you with the technical stack mentioned in the job description?  \n- Are you comfortable learning and experimenting with new AI frameworks and research developments?\n\nOBSERVATIONS:  \n- The candidate’s brief response indicates a possible gap in experience relevant to the core responsibilities of the role.  \n- Given the emphasis on designing and deploying agentic systems, their lack of response raises concerns about their suitability for this position.  \n- To better assess their fit, further clarification on their technical background and willingness to develop expertise in multi-agent AI systems would be necessary.",
      "question_category": "experience"
    },
    {
      "question": "Given your background with LLMs and API integrations, how would you approach experimenting with fine-tuning models like GPT-3 or Gemini for educational content, ensuring both quality and scalability?",
      "response": "aaaa",
      "timestamp": "2025-05-31T15:58:38.058579",
      "score": 4,
      "analysis": "SCORE: 4\n\nSTRENGTHS:\n- Demonstrates experience with GPT-3 integration and deploying AI features at scale, including user engagement metrics.\n- Technical proficiency with relevant tools and frameworks such as Python, Typescript, APIs, and AI stacks.\n- Experience leading experiments with LLMs and deploying AI-powered content generation features.\n\nCONCERNS:\n- The response provided (\"aaaa\") is non-informative, offering no specific approach or methodology related to fine-tuning models like GPT-3 or Gemini.\n- Lacks detail on how the candidate would ensure quality, such as implementing feedback loops, human-in-the-loop systems, or curriculum alignment.\n- No mention of scalability strategies, cost management, or handling iterative model improvements.\n- Does not address collaboration with educators or understanding of content needs, which are critical in an educational context.\n- The previous answer indicates a lack of experience with multi-agent systems, which may be relevant for complex content review workflows.\n\nFOLLOW_UP:\n- Can you describe your specific approach to fine-tuning models like GPT-3 or Gemini for educational content?\n- How would you implement feedback mechanisms to ensure content quality and alignment with curriculum standards?\n- What strategies would you use to scale these models efficiently while managing costs?\n- Have you worked with human-in-the-loop systems to improve model outputs? If so, how?\n\nOBSERVATIONS:\n- The candidate has relevant technical experience but did not elaborate on their approach to experimentation, quality assurance, or scalability in this response.\n- The resume indicates strong engineering skills and some experience with large language models, but the response does not demonstrate strategic thinking around model fine-tuning or content customization.\n- The lack of detail suggests either a gap in experience or an inability to articulate their approach, which is critical for this role involving complex AI systems tailored for education.\n- Overall, the candidate shows potential based on past work but needs to provide more concrete, detailed strategies aligned with the job requirements.",
      "question_category": "technical"
    },
    {
      "question": "In a collaborative environment working with educators and students, how do you balance technical innovation with user feedback to improve AI-driven educational tools, and can you provide an example from your past experience?",
      "response": "bruh",
      "timestamp": "2025-05-31T15:58:46.864823",
      "score": 5,
      "analysis": "SCORE: 1/10\n\nSTRENGTHS:  \n- None evident from the response provided.\n\nCONCERNS:  \n- The response \"bruh\" is non-informative, unprofessional, and does not address the question.  \n- Lacks any demonstration of understanding or experience related to balancing technical innovation with user feedback in educational AI tools.  \n- No mention of collaboration with educators or students, feedback loops, or content quality assurance processes.  \n- Fails to provide any example or insight into past experiences relevant to the role's requirements.\n\nFOLLOW_UP:  \n- Can you describe a specific project where you integrated user feedback into an AI system for education?  \n- How do you ensure that AI-generated content aligns with curriculum standards and user needs?  \n- What strategies have you used to incorporate educator and student feedback into your AI development process?\n\nOBSERVATIONS:  \n- The candidate's response is dismissive and does not engage with the question, which is critical given the role's emphasis on collaboration, feedback, and iterative improvement.  \n- The resume and job description highlight the importance of understanding content needs, implementing feedback loops, and working closely with educators and students—none of which are reflected in this brief reply.  \n- This response raises concerns about the candidate’s professionalism, communication skills, and relevant experience for a role that requires nuanced collaboration and iterative development in educational AI.",
      "question_category": "behavioral"
    }
  ],
  "conversation_history": [
    {
      "role": "interviewer",
      "content": "Can you describe your experience with designing and deploying multi-agent AI systems, particularly in the context of content generation or review, and how you ensured their alignment with specific standards or user needs?"
    },
    {
      "role": "candidate",
      "content": "no"
    },
    {
      "role": "interviewer",
      "content": "Given your background with LLMs and API integrations, how would you approach experimenting with fine-tuning models like GPT-3 or Gemini for educational content, ensuring both quality and scalability?"
    },
    {
      "role": "candidate",
      "content": "aaaa"
    },
    {
      "role": "interviewer",
      "content": "In a collaborative environment working with educators and students, how do you balance technical innovation with user feedback to improve AI-driven educational tools, and can you provide an example from your past experience?"
    },
    {
      "role": "candidate",
      "content": "bruh"
    }
  ],
  "interview_report": "# INTERVIEW REPORT\n\n## CANDIDATE OVERVIEW\nIshmam Ahmed Solaiman is a software engineer with a strong foundation in AI and full-stack development. His background includes research in machine learning, specifically developing AI-powered content discovery and moderation tools utilizing models such as BERT, Gemini, Mistral, and Llama. He has practical experience deploying large language models (LLMs), fine-tuning open-source models, and integrating AI systems into organizational workflows. His technical skill set encompasses Python, TypeScript, JavaScript, Java, React, Node.js, TensorFlow, various databases, cloud services (AWS), containerization (Docker, Kubernetes), and agile methodologies. His prior roles include research assistant at UA Little Rock and software engineering internships at Gainwell Technologies and Optimizely.\n\n## INTERVIEW SUMMARY\nThe candidate demonstrated a solid technical background with relevant experience in deploying AI models and integrating APIs. However, his responses to key questions revealed significant gaps in experience related to the core responsibilities of the role, particularly in designing and deploying multi-agent AI systems and in collaborative, user-centered development processes. His answers lacked depth and specificity, indicating limited practical experience in some of the most critical aspects of the position. Overall, while technically capable, the candidate’s familiarity with the specific domain of agentic content creation frameworks and collaborative educational tools appears limited.\n\n## DETAILED ASSESSMENT\n\n### Technical Skills\nIshmam possesses a broad and relevant technical skill set, including proficiency in Python, TypeScript, APIs, LLM deployment, and cloud infrastructure. His experience with fine-tuning models, building AI pipelines, and integrating various AI frameworks demonstrates strong engineering capabilities. Nonetheless, his responses suggest limited hands-on experience with multi-agent systems, RAG pipelines, or the specific frameworks (e.g., LangChain, Neo4j) emphasized in the role.\n\n### Experience Relevance\nHis research work involving narrative extraction, content moderation, and deploying AI models aligns with some aspects of the role, such as content generation and moderation. However, he explicitly indicated a lack of experience with designing and deploying multi-agent AI systems, which are central to the position’s focus on agentic content creation. His internship projects involved NLP and conversational agents but did not demonstrate experience with scalable, multi-agent frameworks or educational content standards.\n\n### Communication & Soft Skills\nThe candidate’s communication during the interview was minimal and, at times, unprofessional (e.g., brief responses like \"no,\" \"aaaa,\" \"bruh\"). These responses hinder the ability to assess his soft skills, including clarity, professionalism, and collaborative mindset. His lack of elaboration and engagement raises concerns about his ability to effectively communicate complex technical ideas and collaborate with educators and multidisciplinary teams.\n\n### Problem-Solving Ability\nWhile his technical background suggests strong problem-solving skills, his responses to scenario-based questions were superficial. The absence of detailed approaches or strategies indicates a potential gap in strategic thinking and adaptability, especially in complex, multi-faceted projects involving education and AI.\n\n## STRENGTHS\n- Strong foundation in AI and machine learning, with practical experience deploying models like BERT, Gemini, and Llama.\n- Proficiency in relevant programming languages and frameworks (Python, TypeScript, APIs).\n- Experience with integrating AI models into organizational workflows, improving efficiency.\n- Familiarity with cloud services and containerization technologies.\n\n## AREAS OF CONCERN\n- Lack of experience with designing and deploying multi-agent AI systems, which are critical for this role.\n- Limited understanding or demonstration of content review, standards alignment, and collaborative development with educators.\n- Responses to behavioral and scenario questions were brief, unprofessional, or non-informative, raising concerns about communication skills and professionalism.\n- No evidence of experience with agentic frameworks such as LangChain, Neo4j, or multi-agent coordination, which are essential for the position.\n- Potential difficulty in adapting to the role’s emphasis on experimentation, iterative development, and user-centered design.\n\n## RECOMMENDATION\nGiven the candidate’s solid technical background but significant gaps in experience directly related to the core responsibilities of the role, especially in multi-agent systems and collaborative educational content development, it is recommended to **not proceed with an offer at this time**. The candidate may be suitable for roles focusing on AI deployment and engineering but lacks the specific experience and communication skills necessary for a leadership role in developing agentic educational frameworks.\n\n## OVERALL SCORE: 4/10\n\nThis score reflects his technical competence but also accounts for the notable deficiencies in experience relevant to the key responsibilities and the unprofessional nature of some responses. Further development and targeted experience in multi-agent systems and educational content collaboration would be necessary for future consideration.",
  "rag_context": "Collaborate with students and educators to understand content needs and learning styles\nEnsure generated content is aligned with curriculum standards and user-specific learning paths\nImplement feedback loops both AI and Human-In-Loop between generation, review, and QA agents to maximize quality and efficiency\nQualifications\nStrong engineering background (Python/Typescript, API integration, backend frameworks)\n2+ years working with LLMs, multi-agent frameworks, or autonomous AI tools\nJob Description\nWe’re seeking an experienced AI Engineer to help architect and build our agentic content creation framework. You’ll be a core contributor—coding, experimenting, and helping define how AI agents can generate and manage high-quality educational resources aligned to learning standards and personalized learning needs.\nRemote (US Preferred) | Full-time | Reporting to CTO\nWe’re a fast-moving team reimagining education through AI. Our mission is to deliver personalized, adaptive learning experiences that scale. Backed by leading partners and driven by impact, we’re building tools that empower students and educators every day.\n\n\nApply here: https://www.atypicalai.com/jobs/ai-engineer-agentic-frameworks-in-education",
  "next_action": "generate_question",
  "is_complete": true,
  "current_analysis": "SCORE: 1/10\n\nSTRENGTHS:  \n- None evident from the response provided.\n\nCONCERNS:  \n- The response \"bruh\" is non-informative, unprofessional, and does not address the question.  \n- Lacks any demonstration of understanding or experience related to balancing technical innovation with user feedback in educational AI tools.  \n- No mention of collaboration with educators or students, feedback loops, or content quality assurance processes.  \n- Fails to provide any example or insight into past experiences relevant to the role's requirements.\n\nFOLLOW_UP:  \n- Can you describe a specific project where you integrated user feedback into an AI system for education?  \n- How do you ensure that AI-generated content aligns with curriculum standards and user needs?  \n- What strategies have you used to incorporate educator and student feedback into your AI development process?\n\nOBSERVATIONS:  \n- The candidate's response is dismissive and does not engage with the question, which is critical given the role's emphasis on collaboration, feedback, and iterative improvement.  \n- The resume and job description highlight the importance of understanding content needs, implementing feedback loops, and working closely with educators and students—none of which are reflected in this brief reply.  \n- This response raises concerns about the candidate’s professionalism, communication skills, and relevant experience for a role that requires nuanced collaboration and iterative development in educational AI."
}